{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# for matrix manipulation\n",
    "import numpy as np\n",
    "# for deep learning\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "# for negative transform\n",
    "import PIL.ImageOps\n",
    "# for keeping track of training progress\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the LeNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the leNet5 class\n",
    "class leNet5(nn.Module):\n",
    "    # ask for number of input channels because MNIST are B&W and CIFAR is RGB\n",
    "    def __init__(self, dataset):\n",
    "        self.param_dict = {\"mnist\":[1,2],\n",
    "                       \"fashion-mnist\":[1,2],\n",
    "                       \"cifar\":[3,0]}\n",
    "        super(leNet5, self).__init__()\n",
    "        # first conv layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=self.param_dict[dataset][0], out_channels=6, kernel_size=5, stride=1, padding=self.param_dict[dataset][1])\n",
    "        # second conv layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        # first fully connected layer\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        # second fully connected layer\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # third/output fully connected layer\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    # forward function\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        out = self.fc3(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom class to apply negative transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Negative(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        img = 1-img\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to load positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in specified dataset\n",
    "def load_positive(normalize):\n",
    "    if normalize is True:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1285,), (0.3057,))\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1285,), (0.3057,))\n",
    "        ])\n",
    "    elif normalize is False:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "    # download datasets and apply transformations\n",
    "    trainset = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform_train)\n",
    "    testset = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform_test)\n",
    "        \n",
    "    # load the data into loaders to use for the model\n",
    "    trainloader=torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "    testloader=torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # return the train and test loaders\n",
    "    return trainloader, testloader, trainset, testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### helper function to load negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_negative(normalize):\n",
    "    if normalize is True:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            Negative(),\n",
    "            transforms.Normalize((0.8654,), (0.3117,))\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            Negative(),\n",
    "            transforms.Normalize((0.8654,), (0.3117,))\n",
    "        ])\n",
    "        \n",
    "    elif normalize is False:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            Negative(),\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            Negative(),\n",
    "        ])\n",
    "    \n",
    "    # download dataset and apply transformations\n",
    "    trainset = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform_train)\n",
    "    testset = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform_test)\n",
    "        \n",
    "    # load the data into loaders to use for the model\n",
    "    trainloader=torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "    testloader=torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # return the train and test loaders\n",
    "    return trainloader, testloader, trainset, testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### helper function to load a concatenated dataset of postive and negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_concat(normalize):\n",
    "    # load the datasets\n",
    "    _, _, train_pos, test_pos = load_positive(normalize)\n",
    "    _, _, train_neg, test_neg = load_negative(normalize)\n",
    "    \n",
    "    # concatenate the datasets\n",
    "    concat_train = torch.utils.data.ConcatDataset([train_pos, train_neg]) \n",
    "    concat_test = torch.utils.data.ConcatDataset([test_pos, test_neg])\n",
    "    \n",
    "    # construct dataloaders on the concatenated datasets\n",
    "    trainloader = torch.utils.data.DataLoader(concat_train, batch_size=64, shuffle=True, num_workers=2)\n",
    "    testloader = torch.utils.data.DataLoader(concat_test, batch_size=64, shuffle=True, num_workers=2)\n",
    "    \n",
    "    return trainloader, testloader, concat_train, concat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function used to view the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_mnist = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "def imshow(dataset, classes, is_mnist, range_):\n",
    "    #rand_int = random.randint(0,range_)\n",
    "    rand_int = 3849\n",
    "    img = dataset[rand_int][0]\n",
    "    label = dataset[rand_int][1]\n",
    "    if is_mnist is True:\n",
    "        img = img.reshape(28,28)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        np_arr = img.numpy()\n",
    "        plt.imshow(np.transpose(np_arr, (1, 2, 0)), cmap='gray', interpolation='nearest')\n",
    "    plt.show()\n",
    "    print(\"Category: \" + classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the normalized data\n",
    "mnist_train_pos, mnist_test_pos, m_ds_pos, test_pos = load_positive(normalize=True)\n",
    "mnist_train_neg, mnist_test_neg, m_ds_neg, test_neg = load_negative(normalize=True)\n",
    "concat_train, concat_test, concat_ds, concat_ds_test = load_concat(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of positive train: 60000, length of negative train: 60000, length of concat train: 120000\n",
      "length of positive test: 10000, length of negative test: 10000, length of concat test: 20000\n"
     ]
    }
   ],
   "source": [
    "# Print out the lengths of train and test datasets as a sanity check\n",
    "print(f'length of positive train: {len(m_ds_pos)}, length of negative train: {len(m_ds_neg)}, length of concat train: {len(concat_ds)}')\n",
    "print(f'length of positive test: {len(test_pos)}, length of negative test: {len(test_neg)}, length of concat test: {len(concat_ds_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Dataset\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Concatenated Dataset\")\n",
    "imshow(concat_ds, classes_mnist, True, 120000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing a positive mnist item\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Showing a positive mnist item\")\n",
    "imshow(m_ds_pos, classes_mnist, True, 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing a negative mnist item\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Showing a negative mnist item\")\n",
    "imshow(m_ds_neg, classes_mnist, True, 60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Testing functions (Subject to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def train(dataloader, model, loss_fn, opt, num_epochs):\n",
    "    # Loop through all the epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # initialize tqdm for a nice progress bar\n",
    "        loop = tqdm(enumerate(dataloader), total=len(dataloader), leave=True)\n",
    "        # Loop through the dataloader\n",
    "        for batch, (X, y) in loop:\n",
    "            # Prediction error\n",
    "            pred = model(X)          # Forward pass\n",
    "            loss = loss_fn(pred, y)  # Loss calculation\n",
    "\n",
    "            # Backpropagation\n",
    "            opt.zero_grad()          # Zero the gradient\n",
    "            loss.backward()          # Calculate updates\n",
    "            \n",
    "            # Gradient Descent\n",
    "            opt.step()               # Apply updates\n",
    "\n",
    "            # Update progress bar\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            loop.set_postfix(loss = loss.item())\n",
    "\n",
    "# testing function\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    # put the moel in evaluation mode so we aren't storing anything in the graph\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # get the prediction\n",
    "            pred = model(X)\n",
    "            # add to the loss\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # the argmax of the prediction gives us the article of clothing that was predicted, if it matches, add 1 to correct\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LeNet on positive samples and test on negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leNet5(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the neural network\n",
    "leNet = leNet5(dataset=\"mnist\")\n",
    "print(leNet)\n",
    "# define loss function and optimizer\n",
    "loss = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(params=leNet.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for data, label in mnist_train_pos:\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]: 100%|██████████| 938/938 [00:27<00:00, 34.21it/s, loss=0.227] \n",
      "Epoch [2/5]: 100%|██████████| 938/938 [00:23<00:00, 39.25it/s, loss=0.0568]\n",
      "Epoch [3/5]: 100%|██████████| 938/938 [00:19<00:00, 47.28it/s, loss=0.148] \n",
      "Epoch [4/5]: 100%|██████████| 938/938 [00:22<00:00, 42.05it/s, loss=0.025] \n",
      "Epoch [5/5]: 100%|██████████| 938/938 [00:20<00:00, 46.10it/s, loss=0.122]  \n"
     ]
    }
   ],
   "source": [
    "# train for 15 epochs on the positive data\n",
    "train(mnist_train_pos, leNet, loss, opt, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.001133 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test accuracy on positive examples\n",
    "test(mnist_test_pos, leNet, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 14.0%, Avg loss: 0.108542 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test accuracy on negative examples\n",
    "test(mnist_test_neg, leNet, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LeNet-5 on both positive and negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leNet5(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# train on concatenated dataset\n",
    "leNet_concat = leNet5(dataset=\"mnist\")\n",
    "print(leNet_concat)\n",
    "loss_concat = nn.CrossEntropyLoss()\n",
    "opt_concat = torch.optim.Adam(params=leNet_concat.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for data, label in concat_train:\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]:  89%|████████▉ | 1671/1875 [00:43<00:05, 38.55it/s, loss=0.216] "
     ]
    }
   ],
   "source": [
    "# train for 5 epochs on the positive data\n",
    "train(concat_train, leNet_concat, loss_concat, opt_concat, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 65177) is killed by signal: Unknown signal: 0. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-48e95c7e7c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleNet_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-9f3b42e75a91>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;31m# get the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;31m# prime the prefetch loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_queue_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mworker_queue_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notempty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36m_start_thread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'doing self._thread.start()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'... done self._thread.start()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0m_limbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_owned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot wait on un-acquired lock\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mwaiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_allocate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_waiters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 65177) is killed by signal: Unknown signal: 0. "
     ]
    }
   ],
   "source": [
    "test(concat_test, leNet_concat, loss_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Statistics of the positive and negative datasets (pre-normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(loader):\n",
    "      mean = 0.\n",
    "      meansq = 0.\n",
    "      for data, _ in loader:\n",
    "          mean = data.mean()\n",
    "          meansq = (data**2).mean()\n",
    "\n",
    "      std = torch.sqrt(meansq - mean**2)\n",
    "      print(\"mean: \" + str(mean))\n",
    "      print(\"std: \" + str(std))\n",
    "      print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the unnormalized datasets\n",
    "train_pos_unorm, test_pos_unorm, dspos_unorm, dstest_unorm = load_positive(normalize=False)\n",
    "train_neg_unorm, test_neg_unorm, dsneg_unorm, dstest_unorm = load_negative(normalize=False)\n",
    "concat_train_unorm, concat_test_unorm, concat_ds_unorm, concat_ds_test_unorm = load_concat(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing statistics of positive...\n",
      "mean: tensor(0.1285)\n",
      "std: tensor(0.3057)\n",
      "\n",
      "printing statistics of negative...\n",
      "mean: tensor(0.8654)\n",
      "std: tensor(0.3117)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print statistics of postive and negative training sets\n",
    "print(\"printing statistics of positive...\")\n",
    "print_statistics(train_pos_unorm)\n",
    "print(\"printing statistics of negative...\")\n",
    "print_statistics(train_neg_unorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
